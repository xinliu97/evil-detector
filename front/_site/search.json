[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category). We will use “dangerous website” as an example.\n\n\nIdentifying and characterizing “dangerous” websites: What specifc kinds of content and tactics in website cause the websites dangerous? In other words, which ads do people dislike (or like)?\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.\nAnalyze the characteristics of dangerous websites via calsual inference."
  },
  {
    "objectID": "index.html#topic-summary",
    "href": "index.html#topic-summary",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category). We will use “dangerous website” as an example.\n\n\nIdentifying and characterizing “dangerous” websites: What specifc kinds of content and tactics in website cause the websites dangerous? In other words, which ads do people dislike (or like)?\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.\nAnalyze the characteristics of dangerous websites via calsual inference."
  },
  {
    "objectID": "index.html#roadmap",
    "href": "index.html#roadmap",
    "title": "Introduction",
    "section": "Roadmap:",
    "text": "Roadmap:\n\nConstruct a website list which contains dangerous websites and non-dangerous websites.\n\nFigure which feature is the most important for classify a website into a target category.(i.e. What feature can represent a website)\n\nCollect website list (About 200,000 websites).\nDecide which feature is better, collect website features via crawler(Now about 30 features).\n\nConstruct a website list without ground truth.(Core contribution)\n\nDownload some pre-trained model from Huggingface.\nCompare the performance of different models and choose the best one as the teacher model.\nUse the teacher-student model to train a student model.\nUse the student model’s proformance to evaluate the teacher model’s performance and fine-tune the teacher model.\nUse a well-known dataset (AD DataSet) to evaluate our model.\nUse the model to predict the website list.\n\n\nIdentifying and characterizing “dangerous” websites: Initially I will use causal inference to analyze the characteristics of dangerous websites. Crawling the ad, tracker and script information of the website, and then use causal inference to analyze the characteristics of dangerous websites.(NEED TO READ MORE PAPER.)"
  },
  {
    "objectID": "index.html#process",
    "href": "index.html#process",
    "title": "Introduction",
    "section": "Process",
    "text": "Process\n\n1.Collect a list of websites and the data we want to use.\nNow we use data from ISCX-URL2016\nAccording to the reference we can use the following features to identify the category of a website:\n\n\n\n\n\n\n\n\nFeature ID\nVariable Name\nVariable Description\n\n\n\n\n1\nIP_Address_Usage\nIndicates whether the IP address is used as the URL.\n\n\n2\nLong_URL\nReflects if the URL is unusually long to hide suspicious parts.\n\n\n3\nAt_Symbol_In_URL\nDenotes the presence of ‘@’ symbol in the URL.\n\n\n4\nDomain_Prefix_Suffix\nPresence of prefix or suffix in the domain.\n\n\n5\nSub_Domain_Count\nNumber of sub-domains and multi sub-domains.\n\n\n6\nRequest_URL\nThe URL which is requested.\n\n\n7\nAnchor_URL\nThe URL of anchor links in the webpage.\n\n\n8\nAbnormal_URL\nIdentifies if the URL structure is abnormal.\n\n\n9\nLinks_In_Tags\nNumber of links present within tags (like &lt;a&gt;, &lt;img&gt; etc.).\n\n\n10\nWebpage_Title\nThe title of the webpage.\n\n\n11\nMeta_Description\nDescription of the webpage provided in meta tags (if available).\n\n\n12\nRedirect_Page\nIndicates whether the webpage redirects to another page.\n\n\n13\nActive_Content_Presence\nPresence of active content like JavaScript, Flash.\n\n\n14\nTechnology_Stack_Info\nInformation on the technology stack used, analyzed from HTTP headers or page content.\n\n\n15\nHTTP_Header_Info\nInformation provided in the HTTP headers of the webpage.\n\n\n16\nPrivacy_Policy_Presence\nIndicates the presence of Privacy Policy/Terms of Service through text analysis.\n\n\n17\nMobile_Responsiveness\nIndicates whether the webpage is designed responsively for mobile devices.\n\n\n18\nExternal_Links_Count\nNumber of external links present on the webpage by analyzing &lt;a&gt; tags.\n\n\n\nFor fetching the features above, we write a class WebScraper to gethering those data."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Naive Bayes Approach for Website Classification. Link\n\n这篇文章主要是讲了如何用朴素贝叶斯算法来对网站进行分类。\n\nDetecting mailcious urls using lexical analysis Link\n\n这篇文章主要是讲了如何用词法分析来对网站进行分类。利用的特征是URL的语义特征。\n\nPhishing Website Detection With Semantic Features Based on Machine Learning Classifiers:A Comparative StudyLink\nFeature Selection for Phishing Website Classification Link\nSwarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites ClassificationLink\n\n3-5 从URl和网站的内容中提取特征，讲了特征如何选取。\n\n\n\n\n\n\nWeb page classification: Features and algorithms Link\n\nWeb classification 开山鼻祖！明天读完更新这部分内容。\n\nSemi-supervised multi-view graph convolutional networks with application to webpage classificationLink\n\n这篇文章用了semi-supervised multi-view graph convolutional networks来对网站进行分类。效果非常好，但是需要大量已经分类好的数据。\n\n\n\n\n\n\nWhat makes a “bad” ad? user perceptions of problematic online advertising.\n\n这篇文章主要定义了什么是“bad”ad，以及用户对于bad ad的看法。我们在定义危险网站的时候可以参考这篇文章的定义。在分析危险网站的时候，可以参考这篇文章的考量点。Link\n\nOnline tracking: A 1-million-site measurement and analysis.\n\n学习如何分析Trackers. 借助这个工具可以分析网站的trackers. Link Code\n\nDark Web Illegal Activities Crawling and Classifying Using Data Mining Techniques\n\n这篇文章主要是讲了如何用数据挖掘的方法来对暗网进行分类。叙述了暗网的定义。Link"
  },
  {
    "objectID": "references.html#feature-selection.",
    "href": "references.html#feature-selection.",
    "title": "References",
    "section": "",
    "text": "Naive Bayes Approach for Website Classification. Link\n\n这篇文章主要是讲了如何用朴素贝叶斯算法来对网站进行分类。\n\nDetecting mailcious urls using lexical analysis Link\n\n这篇文章主要是讲了如何用词法分析来对网站进行分类。利用的特征是URL的语义特征。\n\nPhishing Website Detection With Semantic Features Based on Machine Learning Classifiers:A Comparative StudyLink\nFeature Selection for Phishing Website Classification Link\nSwarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites ClassificationLink\n\n3-5 从URl和网站的内容中提取特征，讲了特征如何选取。"
  },
  {
    "objectID": "references.html#website-classification",
    "href": "references.html#website-classification",
    "title": "References",
    "section": "",
    "text": "Web page classification: Features and algorithms Link\n\nWeb classification 开山鼻祖！明天读完更新这部分内容。\n\nSemi-supervised multi-view graph convolutional networks with application to webpage classificationLink\n\n这篇文章用了semi-supervised multi-view graph convolutional networks来对网站进行分类。效果非常好，但是需要大量已经分类好的数据。"
  },
  {
    "objectID": "references.html#characterizing-the-dangerous-web",
    "href": "references.html#characterizing-the-dangerous-web",
    "title": "References",
    "section": "",
    "text": "What makes a “bad” ad? user perceptions of problematic online advertising.\n\n这篇文章主要定义了什么是“bad”ad，以及用户对于bad ad的看法。我们在定义危险网站的时候可以参考这篇文章的定义。在分析危险网站的时候，可以参考这篇文章的考量点。Link\n\nOnline tracking: A 1-million-site measurement and analysis.\n\n学习如何分析Trackers. 借助这个工具可以分析网站的trackers. Link Code\n\nDark Web Illegal Activities Crawling and Classifying Using Data Mining Techniques\n\n这篇文章主要是讲了如何用数据挖掘的方法来对暗网进行分类。叙述了暗网的定义。Link"
  }
]