[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category).\n\n\nIdentifying and characterizing “dangerous” websites(Or AD website): What specifc kinds of content and tactics in website cause the websites dangerous? In other word, what are the characteristics of dangerous websites have in common? We will use “dangerous website” as an example.\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.(We will use “Whether a website is dangerous” as an example. Or we can use “Whether a website is a ad website” as an example.)\nAnalyze the characteristics of dangerous websites via calsual inference.(Or other techniques, not sure yet.)"
  },
  {
    "objectID": "index.html#topic-summary",
    "href": "index.html#topic-summary",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category).\n\n\nIdentifying and characterizing “dangerous” websites(Or AD website): What specifc kinds of content and tactics in website cause the websites dangerous? In other word, what are the characteristics of dangerous websites have in common? We will use “dangerous website” as an example.\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.(We will use “Whether a website is dangerous” as an example. Or we can use “Whether a website is a ad website” as an example.)\nAnalyze the characteristics of dangerous websites via calsual inference.(Or other techniques, not sure yet.)"
  },
  {
    "objectID": "index.html#roadmap",
    "href": "index.html#roadmap",
    "title": "Introduction",
    "section": "Roadmap:",
    "text": "Roadmap:\n\nConstruct a website list which contains dangerous websites and non-dangerous websites.\n\nFigure which feature is the most important for classify a website into a target category.(i.e. What feature can represent a website)\n\nCollect website list (About 200,000 websites).\nDecide which feature is better, collect website features via crawler(Now about 30 features).\n\nConstruct a website list without ground truth.(Core contribution)\n\nDownload some pre-trained model from Huggingface.\nCompare the performance of different models and choose the best one as the teacher model.\nUse the teacher-student model to train a student model.\nUse the student model’s proformance to evaluate the teacher model’s performance and fine-tune the teacher model.\nUse a well-known dataset (AD DataSet) to evaluate our model.\nUse the model to predict the website list.\n\n\nIdentifying and characterizing “dangerous” websites: Initially I will use causal inference to analyze the characteristics of dangerous websites. Crawling the ad, tracker and script information of the website, and then use causal inference to analyze the characteristics of dangerous websites.(NEED TO READ MORE PAPER.)\n\n\n\n\n\nflowchart TB\n    FEAT(Features) --&gt; CRAWLAR[Crawlar]\n    URL_LIST(Website URL List) --&gt; CRAWLAR\n    CRAWLAR --&gt; FEATURE_DATA(Website Features List)\n    FEATURE_DATA --&gt; TEACHER[Teacher Model]\n  subgraph border[ ]\n    style border fill:#FFFFFF, stroke-dasharray: 5, 5;\n    TEACHER\n    TEACHER --&gt; D[Psudo_labdel]\n    D --&gt; E[Student Model]\n    E --&gt; F(Train & Test)\n    F --&gt; ERROR(Error V1)\n    I[Strong Label] --&gt; F\n  end\n    TEACHER --&gt; TEACHER_PROFORMANCE((Model Proformance))\n    WEB_KB_DATASET(Web KB Dataset) --&gt; TEACHER_PROFORMANCE\n    ERROR -. \"finetune\" .-&gt; TEACHER\n    D -. \"manually review\" .-&gt; RAEL_DANGEROUS((Dangerous website))\n    style FEAT fill:#d3d3d3\n    style D fill:#d3d3d3\n    style I fill:#d3d3d3\n    style WEB_KB_DATASET fill:#d3d3d3\n    style TEACHER_PROFORMANCE fill:#a5a5a5\n    style RAEL_DANGEROUS fill:#a5a5a5"
  },
  {
    "objectID": "index.html#process",
    "href": "index.html#process",
    "title": "Introduction",
    "section": "Process",
    "text": "Process\n\n1.Collect a list of websites and the data we want to use.\nNow we use data from ISCX-URL2016\nIn website classification problem, we have 4 types of features to classify a website:\n\nURL features: URL features are the features that can be extracted from the URL of the website. For example, the length of the URL, the presence of special characters, the presence of an IP address, etc.\nOn page features: On page features are the features that can be extracted from the content of the website. For example, the presence of certain keywords, the presence of certain HTML tags, etc.\nJavaScript features: JavaScript features are the features that can be extracted from the JavaScript code of the website. For example, the presence of certain keywords, the presence of certain functions, etc.\nConnection features: Connection features are other website that have a connection with the website. (Increase computational complexity badly, do not use)\nUser features: User features are the features that can be extracted from the user of the website. For example, the location of the user, the browser used by the user, etc. (Do not do research on this feature. But will use in future)\n\nAccording to the reference we can use the following features to identify the category of a website:\n\n\n\n\n\n\n\n\nFeature ID\nVariable Name\nVariable Description\n\n\n\n\n1\nIP_Address_Usage\nIndicates whether the IP address is used as the URL.\n\n\n2\nLong_URL\nReflects if the URL is unusually long to hide suspicious parts.\n\n\n3\nAt_Symbol_In_URL\nDenotes the presence of ‘@’ symbol in the URL.\n\n\n4\nDomain_Prefix_Suffix\nPresence of prefix or suffix in the domain.\n\n\n5\nSub_Domain_Count\nNumber of sub-domains and multi sub-domains.\n\n\n6\nRequest_URL\nThe URL which is requested.\n\n\n7\nAnchor_URL\nThe URL of anchor links in the webpage.\n\n\n8\nAbnormal_URL\nIdentifies if the URL structure is abnormal.\n\n\n9\nLinks_In_Tags\nNumber of links present within tags (like &lt;a&gt;, &lt;img&gt; etc.).\n\n\n10\nWebpage_Title\nThe title of the webpage.\n\n\n11\nMeta_Description\nDescription of the webpage provided in meta tags (if available).\n\n\n12\nRedirect_Page\nIndicates whether the webpage redirects to another page.\n\n\n13\nActive_Content_Presence\nPresence of active content like JavaScript, Flash.\n\n\n14\nTechnology_Stack_Info\nInformation on the technology stack used, analyzed from HTTP headers or page content.\n\n\n15\nHTTP_Header_Info\nInformation provided in the HTTP headers of the webpage.\n\n\n16\nPrivacy_Policy_Presence\nIndicates the presence of Privacy Policy/Terms of Service through text analysis.\n\n\n17\nMobile_Responsiveness\nIndicates whether the webpage is designed responsively for mobile devices.\n\n\n18\nExternal_Links_Count\nNumber of external links present on the webpage by analyzing &lt;a&gt; tags.\n\n\n\nFor fetching the features above, we write a class WebScraper to gethering those data.\n\n\nPreprocessing the data.\n\nTokenize the text data in features."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Naive Bayes Approach for Website Classification. Link\n\nThis paper talked use naive-Bayes to classify websites.\n\nDetecting mailcious urls using lexical analysis Link\n\nThis paper is mainly about how to use lexical analysis to classify websites. The feature utilized is the semantic feature of the URL.\n\nPhishing Website Detection With Semantic Features Based on Machine Learning Classifiers:A Comparative StudyLink\nFeature Selection for Phishing Website Classification Link\nSwarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites ClassificationLink\n\n3-5 Talked about on-page feature and url feature.\n\n\n\n\n\n\nWeb page classification: Features and algorithms Link\n\nWeb classification 开山鼻祖！明天读完更新这部分内容。\nThis paper mainly talk about the defination web classification，types of it 。and which type of feature can represent a website。\nWebsite classification problem Definition : The process of assigning a Web page to one or more predefined categories based on its content.\nWeb page classification type:\n\nAccording subject:\n\nGeneral web page classification: classify web page into general categories, such as sports, news, and entertainment.\nDomain-specific web page classification: classify web page into domain-specific categories, such as computer, health, and business.\n\nAccording to function: e.g. personal web page, commercial web page, and educational web page.\nAccording to sentiment: e.g. positive, negative, and neutral.\nAccording to the number of class we can divide web page classification into two types: binary classification and multi-class classification.\nAccording to the number of labels we can divide web page classification into two types: single-label classification and multi-label classification.\n\nFeature on webpage classification problem.\n\nOn-page Features:\n\nTextural content and Tags.\nVisual Analysis.\n\nFeature of Neighboring Web Pages: (Increase compuutation complexity, do not use.)\n\nLink Analysis.\nWeb Page Popularity.\n\n\n\nWeb-page Classification through Summarization Link\n\nThis article describes how to use HTML’s summarization tag to classify web pages.\n\nSemi-supervised multi-view graph convolutional networks with application to webpage classificationLink\n\n* This article uses semi-supervised multi-view graph convolutional networks to classify websites. It works very well, but it requires a lot of data that has already been sorted.\n\n\n\n\nWhat makes a “bad” ad? user perceptions of problematic online advertising.\n\nThis article mainly defines what a “bad” ad is and how users perceive bad ad. We can refer to the definition of this article when defining dangerous websites. Consider this article’s considerations when analyzing dangerous websites.Link\n\nOnline tracking: A 1-million-site measurement and analysis.\n\nLearn how to analyze Trackers. Can you analyze trackers on your website with this tool. Link Code\n\nDark Web Illegal Activities Crawling and Classifying Using Data Mining Techniques\n\n这篇文章主要是讲了如何用数据挖掘的方法来对暗网进行分类。叙述了暗网的定义。Link\n\n\n\n\n\n\nA Teacher-Student Framework With Adversarial Learning for Chinese Webpage Classification Link\n\nThis article is mainly about how to use Teacher-Student Network to classify websites."
  },
  {
    "objectID": "references.html#feature-selection.",
    "href": "references.html#feature-selection.",
    "title": "References",
    "section": "",
    "text": "Naive Bayes Approach for Website Classification. Link\n\nThis paper talked use naive-Bayes to classify websites.\n\nDetecting mailcious urls using lexical analysis Link\n\nThis paper is mainly about how to use lexical analysis to classify websites. The feature utilized is the semantic feature of the URL.\n\nPhishing Website Detection With Semantic Features Based on Machine Learning Classifiers:A Comparative StudyLink\nFeature Selection for Phishing Website Classification Link\nSwarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites ClassificationLink\n\n3-5 Talked about on-page feature and url feature."
  },
  {
    "objectID": "references.html#website-classification",
    "href": "references.html#website-classification",
    "title": "References",
    "section": "",
    "text": "Web page classification: Features and algorithms Link\n\nWeb classification 开山鼻祖！明天读完更新这部分内容。\nThis paper mainly talk about the defination web classification，types of it 。and which type of feature can represent a website。\nWebsite classification problem Definition : The process of assigning a Web page to one or more predefined categories based on its content.\nWeb page classification type:\n\nAccording subject:\n\nGeneral web page classification: classify web page into general categories, such as sports, news, and entertainment.\nDomain-specific web page classification: classify web page into domain-specific categories, such as computer, health, and business.\n\nAccording to function: e.g. personal web page, commercial web page, and educational web page.\nAccording to sentiment: e.g. positive, negative, and neutral.\nAccording to the number of class we can divide web page classification into two types: binary classification and multi-class classification.\nAccording to the number of labels we can divide web page classification into two types: single-label classification and multi-label classification.\n\nFeature on webpage classification problem.\n\nOn-page Features:\n\nTextural content and Tags.\nVisual Analysis.\n\nFeature of Neighboring Web Pages: (Increase compuutation complexity, do not use.)\n\nLink Analysis.\nWeb Page Popularity.\n\n\n\nWeb-page Classification through Summarization Link\n\nThis article describes how to use HTML’s summarization tag to classify web pages.\n\nSemi-supervised multi-view graph convolutional networks with application to webpage classificationLink\n\n* This article uses semi-supervised multi-view graph convolutional networks to classify websites. It works very well, but it requires a lot of data that has already been sorted."
  },
  {
    "objectID": "references.html#characterizing-the-dangerous-web",
    "href": "references.html#characterizing-the-dangerous-web",
    "title": "References",
    "section": "",
    "text": "What makes a “bad” ad? user perceptions of problematic online advertising.\n\nThis article mainly defines what a “bad” ad is and how users perceive bad ad. We can refer to the definition of this article when defining dangerous websites. Consider this article’s considerations when analyzing dangerous websites.Link\n\nOnline tracking: A 1-million-site measurement and analysis.\n\nLearn how to analyze Trackers. Can you analyze trackers on your website with this tool. Link Code\n\nDark Web Illegal Activities Crawling and Classifying Using Data Mining Techniques\n\n这篇文章主要是讲了如何用数据挖掘的方法来对暗网进行分类。叙述了暗网的定义。Link"
  },
  {
    "objectID": "references.html#teacher-student-network",
    "href": "references.html#teacher-student-network",
    "title": "References",
    "section": "",
    "text": "A Teacher-Student Framework With Adversarial Learning for Chinese Webpage Classification Link\n\nThis article is mainly about how to use Teacher-Student Network to classify websites."
  }
]