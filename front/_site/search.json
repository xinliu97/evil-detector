[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category). We will use “dangerous website” as an example.\n\n\nIdentifying and characterizing “dangerous” websites: What specifc kinds of content and tactics in website cause the websites dangerous? In other words, which ads do people dislike (or like)?\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.\nAnalyze the characteristics of dangerous websites via calsual inference."
  },
  {
    "objectID": "index.html#topic-summary",
    "href": "index.html#topic-summary",
    "title": "Introduction",
    "section": "",
    "text": "In this project I aim to develop a generalizable novel methodology for identifying website list in a target category. And I will use “dangerous website” as an example to demonstrate my methodology. Finally I will analyze the characteristics of dangerous websites via calsual inference.\nTo be more specific, I will answer the following questions in this project:\n\n\nHow to ascertain whether a website belongs to a specific website category without having a dataset? Not every classification comes with a “ground truth” available for our study. Therefore, I aim to develop a method to determine whether a website falls into a given category in the absence of “ground truth”.(i.e. Input: Category defination, website list. Output: Website which belongs to this category). We will use “dangerous website” as an example.\n\n\nIdentifying and characterizing “dangerous” websites: What specifc kinds of content and tactics in website cause the websites dangerous? In other words, which ads do people dislike (or like)?\n\n\nThis project’s contribution will be:\n\nDevelop a generalizable novel methodology for identifying website list in a target category without ground truth.\nAnalyze the characteristics of dangerous websites via calsual inference."
  },
  {
    "objectID": "index.html#roadmap",
    "href": "index.html#roadmap",
    "title": "Introduction",
    "section": "Roadmap:",
    "text": "Roadmap:\n\nConstruct a website list which contains dangerous websites and non-dangerous websites.\n\nFigure which feature is the most important for classify a website into a target category.(i.e. What feature can represent a website)\n\nCollect website list (About 200,000 websites).\nDecide which feature is better, collect website features via crawler(Now about 30 features).\n\nConstruct a website list without ground truth.(Core contribution)\n\nDownload some pre-trained model from Huggingface.\nCompare the performance of different models and choose the best one as the teacher model.\nUse the teacher-student model to train a student model.\nUse the student model’s proformance to evaluate the teacher model’s performance and fine-tune the teacher model.\nUse a well-known dataset (AD DataSet) to evaluate our model.\nUse the model to predict the website list.\n\n\nIdentifying and characterizing “dangerous” websites: Initially I will use causal inference to analyze the characteristics of dangerous websites. Crawling the ad, tracker and script information of the website, and then use causal inference to analyze the characteristics of dangerous websites.(NEED TO READ MORE PAPER.)"
  },
  {
    "objectID": "index.html#process",
    "href": "index.html#process",
    "title": "Introduction",
    "section": "Process",
    "text": "Process\n\n1.Collect a list of websites and the data we want to use.\nNow we use data from ISCX-URL2016\nAccording to the reference we can use the following features to identify the category of a website:\n\n\n\n\n\n\n\n\nFeature ID\nVariable Name\nVariable Description\n\n\n\n\n1\nIP_Address_Usage\nIndicates whether the IP address is used as the URL.\n\n\n2\nLong_URL\nReflects if the URL is unusually long to hide suspicious parts.\n\n\n3\nAt_Symbol_In_URL\nDenotes the presence of ‘@’ symbol in the URL.\n\n\n4\nDomain_Prefix_Suffix\nPresence of prefix or suffix in the domain.\n\n\n5\nSub_Domain_Count\nNumber of sub-domains and multi sub-domains.\n\n\n6\nRequest_URL\nThe URL which is requested.\n\n\n7\nAnchor_URL\nThe URL of anchor links in the webpage.\n\n\n8\nAbnormal_URL\nIdentifies if the URL structure is abnormal.\n\n\n9\nLinks_In_Tags\nNumber of links present within tags (like &lt;a&gt;, &lt;img&gt; etc.).\n\n\n10\nWebpage_Title\nThe title of the webpage.\n\n\n11\nMeta_Description\nDescription of the webpage provided in meta tags (if available).\n\n\n12\nRedirect_Page\nIndicates whether the webpage redirects to another page.\n\n\n13\nActive_Content_Presence\nPresence of active content like JavaScript, Flash.\n\n\n14\nTechnology_Stack_Info\nInformation on the technology stack used, analyzed from HTTP headers or page content.\n\n\n15\nHTTP_Header_Info\nInformation provided in the HTTP headers of the webpage.\n\n\n16\nPrivacy_Policy_Presence\nIndicates the presence of Privacy Policy/Terms of Service through text analysis.\n\n\n17\nMobile_Responsiveness\nIndicates whether the webpage is designed responsively for mobile devices.\n\n\n18\nExternal_Links_Count\nNumber of external links present on the webpage by analyzing &lt;a&gt; tags.\n\n\n\nFor fetching the features above, we write a class WebScraper to gethering those data."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "references.html#reference",
    "href": "references.html#reference",
    "title": "References",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "references.html#data-set",
    "href": "references.html#data-set",
    "title": "References",
    "section": "Data Set",
    "text": "Data Set\n\nWebKB DataSet:\n-WebKB dataset contains 1051 webpages collected from four universities. These webpages are categorized into the course class and the non-course class. The first class contains 230 pages and the other class consists of the remaining 821 pages. In WebKB, page is characterized by two views, i.e., the page view and the link view. The page view contains the textual content on the page, and the link view contains the hyperlinks pointing to the page.\nAD DataSet:\n-AD dataset contains 3279 samples from two categories, i.e., advertisement class and the non-advertisement class, which are collected from the UCI machine learning repository.\nISCX-URL2016\n-This dataset contains over 110,000 urls. And devide those url into 5 categories: benign, phishing, spam, defacement, malware. We will use this dataset as our training dataset."
  }
]